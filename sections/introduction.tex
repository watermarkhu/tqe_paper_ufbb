\section{Introduction}\label{sec:introduction}
One of the most promising approaches for fault-tolerant quantum computation is based on surface quantum error-correcting codes \cite{dennis2002topological, kitaev2003fault}. With surface codes, error correction only requires the measurement of local operators on a 2-dimensional lattice of qubits. The measurement outcome, called the syndrome, is passed to the decoding algorithm to deduct the error that has occurred and to supply a correction operator. The resilience against errors can be improved by increasing the system size while the physical error rate is below a threshold value $p_{th}$. For this, it is essential that the decoder has low time complexity; if the clock-rate of the quantum computer becomes limited by the decoder, the advantages of increasing the system size could be compromised.

Many decoding algorithms have been developed that either aim to improve the threshold and lower logical error rates \cites{wang2003confinement, raussendorf2007faulttolerant, fowler2012towards, fowler2013minimum, heim2016optimal, duclos2010fast, duclos2013fault, bravyi2014efficient, darmawan2018linear}, or to perform under more realistic noise models \cites{tuckett2020fault, hutter2015improved, bravyi2013quantum,  nickerson2019analysing, wootton2012high, huang2020fault}, including a new class of neural network decoders \cites{baireuther2019neural, chamberland2018deep, liu2019neural, nautrup2019optimizing, torlai2017neural, varsamopoulos2017decoding, varsamopoulos2020decoding}, and other types \cites{bombin2012universal, herold2015cellular, horsman2012surface, kubica2019cellular, watson2015fast}. Identifying the optimal decoder of the code depends critically on the noise model. The most popular decoder for surface codes is unarguably still the Minimum-Weight Perfect Matching (MWPM) decoder. It performs near-optimal for a bit-flip noise model \cite{dennis2002topological} on a standard non-bounded surface code with a threshold of $p_{th} = 10.3\%$, and for a phenomenological noise model \cite{wang2003confinement}, which includes faulty measurements, with $p_{th} = 2.9\%$. This approach's basic principle is to identify the \emph{lowest weight} error configuration that can produce the syndrome. The minimum-weight matching is found by constructing a fully connected graph between nodes of the syndrome, which leads to a cubic worst-case time complexity of $\mathcal{O}(n^3)$, where $n$ is the number of qubits in the system \cite{kolmogorov2009blossom}. Fowler has proved that the matching problem can be solved in average $\mathcal{O}(1)$ time, but only at sufficiently low error rates, and the worst-case complexity remains significant \cite{fowler2013minimum}. 

In this work, we build on top of a recently proposed decoder called the Union-Find (UF) decoder. It combines a very low worst-case time complexity with a high threshold \cites{delfosse2017almost}, making it a practical solution for real devices. The UF decoder's thresholds on the toric code with independent bit-flip noise and phenomenological noise are $9.9\%$ and $2.7\%$, and its worst-case time complexity is $\mathcal{O}(n\alpha(n))$, where $\alpha$ is the inverse of Ackermann's function \cite{tarjan1975efficiency}. For any physically feasible amount of qubits, this value is $\alpha(n) \leq 3$, leading to an ``almost-linear'' time complexity.

We propose here a modification of the UF decoder that improves the heuristic for minimum-weight matching. The modified decoder, which we dub the \emph{Union-Find Node-Suspension decoder} (UFNS), achieves near MWPM performance while retaining a quasilinear time complexity. In sections \Cref{sec:surfacecode,sec:unionfind}, we introduce the surface code and the UF decoder. In \Cref{sec:ufbb}, we describe the modified algorithm and its motivation. We discuss the algorithm's complexity in \Cref{sec:complexity} and compare its performance with other decoders in \Cref{sec:performance}.  

\section{The Surface Code}\label{sec:surfacecode}

The Union-Find Node-Suspension decoder proposed here, similarly to its parent decoder, applies to any surface code of any genus, with or without boundary, and to color codes \cite{delfosse2017almost}. For simplicity, we only describe the standard implementation of the surface code without boundary.

The \emph{toric code}, a topological code introduced by Kitaev \cite{kitaev2003fault}, is defined by arranging qubits on the edges of a square lattice with periodic boundary conditions. The code is denoted by $V,E,F$, respectively the set of vertices, set of edges, and the set of faces on the lattice. The toric code is defined to be the ground state of the Hamiltonian 
\begin{equation}
    H = -\sum_{v \in V} X_v -\sum_{f \in F} Z_f, 
\end{equation}
where operator $X_v$ is the product of Pauli $X$ operators on the qubits located on edges forming the vertex $v$, \emph{i.e.}, $X_v = \prod_{e \in v} X_e$, and $Z_f = \prod_{e \in f} Z_e$ is the product of Pauli $Z$ operators on the qubits located on edges of face $f$. The code space is spanned by the simultaneous ``+1'' eigenstate of all operators $X_v$ and $Z_f$. Together with any possible product of them, these operators are the \emph{stabilizers} of the code and form the stabilizer group $S$. The torus' non-trivial cycles encode the logical operators. Below a certain threshold, errors will only introduce local effects and do not change these cycles.

For simplicity, we consider independent or non-correlated noise caused by i.i.d. bit-flip errors, where each qubit is subjected to a Pauli $X$ error with probability $p_X$. Due to \emph{lattice duality}, the error detection and correction of phase-flip errors are identical. The phenomenological noise model adds noisy measurements with the probability of error during each measurement equal to $p_X$. 
%Additionally, any qubit may be \emph{erased} from the system with probability $p_e$. The set of erased qubits is denoted with $\varepsilon$. This \emph{erasure} is detectable, such that we can replace or reinitiate all erased qubits, which corresponds to a random Pauli error after measurement. 

Error correction is proceeded by measuring a set of independent stabilizers of the code, \emph{i.e.}, the operators $X_v$ and $Z_f$. For a set of phase-flip errors $E_Z = \{I,Z\}^{\otimes n}$, the stabilizers $X_v$ that anticommute with the error return a non-trivial outcome. The set of non-trivial eigenvalues of the stabilizers is called the syndrome $\sigma$ of the code. Given the measured $\sigma$, it is the task of the decoder to find the correction operator $\mathcal{C}(\sigma)$. When the correction operator is applied, the code is returned to the code space, \emph{i.e.}, $\mathcal{C}(\sigma)E_Z \in S$. The error is corrected up to a stabilizer. The mapping of the measured syndrome to the correction is thus not one-to-one. It is up to the decoder to choose the correction most similar to the error. 

\section{Union-Find decoder}\label{sec:unionfind}

The Union-Find decoder \cite{delfosse2017almost} maps each element of the syndrome $\sigma$ to a so-called non-trivial vertex $v$ in a non-connected graph on the code lattice, and grows clusters that form a connected graph $G(V_i, E_i)$ of vertices $V_i\in V$ and edges $E_i \in E$ locally, by repeatedly adding a layer of edges and trivial vertices to existing clusters, until all clusters have an even number of non-trivial syndrome vertices. This process is described as the growth of a cluster or the growth of the vertices that lie on a cluster's boundary. Then, a spanning tree $F$ is built, such that each cluster is a connected acyclic graph., Leaves of the trees are conditionally peeled in a tail-recursive breadth-first search until all non-trivial syndrome vertices are paired and linked by a path within $F$, which is the correcting operator $\mathcal{C}$ \cite{delfosse2017linear}. By growing the clusters of vertices in order of their sizes --- the number of vertices in the cluster --- the threshold is reported to increase from $9.2\%$ to $9.9\%$ for bit-flip noise in this \textbf{Weighted Growth} variant of the decoder.

The merging between clusters drives the complexity of the Union-Find decoder. For this, the algorithm uses the Union-Find or disjoint-set data structure \cite{tarjan1975efficiency}. The function $\codefunc{Find}(v)$ is used to travel in the cluster-tree --- a disjoint set of the cluster's vertices --- from vertex $v$ to the representative root element $r_v$, to identify the cluster to which $v$ belongs. When two vertices $u, v$ are connected on a newly added edge $(u,v)$, $\codefunc{Find}(u), \codefunc{Find}(v)$ output the roots $r_u, r_v$. If $r_u \neq r_v$, the two cluster-trees are not connected. The two cluster are then mergeds by $\codefunc{Union}(r_u, r_v)$ by pointing one tree's root to another root. \textbf{Weighted Union} is performed by pointing the smaller tree to the larger to reduce the cost of future calls to \codefunc{Find}.